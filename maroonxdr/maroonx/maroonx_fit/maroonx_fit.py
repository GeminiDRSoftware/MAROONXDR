'''
This module contains the functions that are used to fit the etalon spectrum, and then
extract the peak parameters and polynomial parameters from the fit results.
'''
import os
import pickle
import time
import numpy as np
import matplotlib.pyplot as plt

import pandas as pd
from gempy.utils import logutils

from .maroon_x_fit_object import MaroonXFit, FitResult

PLOT_FORMAT = "png"

def insert_peak_parameters(results):
    """
    Extract the parameters for each peak.

    Parameters
    ----------
    results: list of FitResults NamedTuple
        Results of the fits generated by iterative fit

    Returns
    -------
    peaks: A pandas dataframe that can be converted to a fits table
    """
    peaks = pd.DataFrame()

     # Making the empty columns
    fiber_list = []
    order_list = []
    offset_list = []
    center_list = []
    amplitude_list = []
    sigma1_list = []
    sigma2_list = []
    width_list = []
    recorded_list = []
    lq_cost_list = []
    lq_status_list = []

    for result in results:

        # Unpack necessary parameters

        result_obj = result.fit_obj
        parameters = result_obj.param_obj

        offset = parameters.offset
        fits = parameters.eval_polynomials_at_centers()

        for values, f in zip(fits.T, result.peak_fit_results):
            center, amplitude, sigma1, sigma2, width = values

            # Append the values to the columns
            fiber_list.append(result.fiber)
            order_list.append(result.order)
            offset_list.append(offset)
            center_list.append(center)
            amplitude_list.append(amplitude)
            sigma1_list.append(sigma1)
            sigma2_list.append(sigma2)
            width_list.append(width)
            recorded_list.append(result.recording_time)
            lq_cost_list.append(f.cost)
            lq_status_list.append(f.status)

    # Insert the columns into the dataframe
    peaks['FIBER'] = fiber_list
    peaks['ORDER'] = order_list
    peaks['OFFSET'] = offset_list
    peaks['CENTER'] = center_list
    peaks['AMPLITUDE'] = amplitude_list
    peaks['SIGMA1'] = sigma1_list
    peaks['SIGMA2'] = sigma2_list
    peaks['WIDTH'] = width_list
    peaks['RECORDED'] = recorded_list
    peaks['LQ_COST'] = lq_cost_list
    peaks['LQ_STATUS'] = lq_status_list

    return peaks

def insert_polynomial_parameters(results):
    """
    Extract polynomial parameters from results.

    Parameters
    ----------
    results: FitResults NamedTuple
        Results of the fits generated by iterative fit

    """
    result_obj_0 = results[0].fit_obj
    meta_parameters = result_obj_0.param_obj.meta_parameters

    #Check valid meta_parameters.  Do not check total and number of peaks.
    for result in results:
        result_obj = result.fit_obj
        if not result_obj.param_obj.meta_parameters.sigma == meta_parameters.sigma\
            and result_obj.param_obj.meta_parameters.width == meta_parameters.width\
            and result_obj.param_obj.meta_parameters.use_sigma_lr == meta_parameters.use_sigma_lr:
            raise ValueError('All meta_parameters must be the same')

    poly = pd.DataFrame()
    # Make the empty columns
    recorded_list = []
    fiber_list = []
    order_list = []
    fitrange_list = []
    offset_list = []
    lq_cost_list = []
    lq_status_list = []
    if meta_parameters.use_sigma_lr:
        sigma_l_coefficients_list = []
        sigma_r_coefficients_list = []
    else:
        sigma_coefficients_list = []
    width_coefficients_list = []

    # Get the polynomial parameters and insert into dataframe
    for result in results:
        result_obj = result.fit_obj
        values = result_obj.param_obj.split_parameters()
        offset, p_sigma_l, p_sigma_r, p_width, _, _ = values

        f = result.polynomial_fit_result

        # Append the values to the columns
        recorded_list.append(result.recording_time)
        fiber_list.append(result.fiber)
        order_list.append(result.order)

        # Convert the fitrange to a string to store in the fits table
        fit_obj = result.fit_obj
        fitrange = [fit_obj.fitrange[0], fit_obj.fitrange[-1] + 1]
        fitrange_str = ','.join([str(x) for x in fitrange])
        fitrange_list.append(fitrange_str)

        offset_list.append(offset)
        lq_cost_list.append(f.cost)
        lq_status_list.append(f.status)
        if meta_parameters.use_sigma_lr:
            # Convert the list of coefficients to a string to store in the fits table
            sigma_l_coefficients_str = ','.join([str(x) for x in list(p_sigma_l)])
            sigma_r_coefficients_str = ','.join([str(x) for x in list(p_sigma_r)])
            sigma_l_coefficients_list.append(sigma_l_coefficients_str)
            sigma_r_coefficients_list.append(sigma_r_coefficients_str)

        else:
            sigma_coefficients_str = ','.join([str(x) for x in list(p_sigma_l)])
            sigma_coefficients_list.append(sigma_coefficients_str)

        width_coefficients_str = ','.join([str(x) for x in list(p_width)])
        width_coefficients_list.append(width_coefficients_str)

    # Insert the columns into the dataframe
    poly['recorded'] = recorded_list
    poly['fiber'] = fiber_list
    poly['order'] = order_list
    poly['fitrange'] = fitrange_list
    poly['offset'] = offset_list
    poly['lq_cost'] = lq_cost_list
    poly['lq_status'] = lq_status_list
    if meta_parameters.use_sigma_lr:
        poly['sigma_l_coefficients'] = sigma_l_coefficients_list
        poly['sigma_r_coefficients'] = sigma_r_coefficients_list
    else:
        poly['sigma_coefficients'] = sigma_coefficients_list
    poly['width_coefficients'] = width_coefficients_list

    return poly

def calculate_residuals(observed, predicted, sigma = 3, bad_flag = True):
    """
    A small helper function used in the iterative code to calculate residuals,
    It then normalizes the residuals by the number of samples.
    """

    log = logutils.get_logger(__name__)
    residuals = np.abs((predicted-observed)/predicted)

    # If bad = True, clip extreme outliers immediately
    if bad_flag:
        bad = np.where(residuals > 2)

    residuals = np.clip(residuals,0,2)
    residuals[np.where(residuals >  sigma * np.nanstd(residuals))] = np.nan

    if bad_flag:
        observed[bad] = np.nan
        num_bad = np.count_nonzero(bad)
        log.info(f"Clip {num_bad} datapoints as outliers when calculating residuals")

    residuals = np.nansum(residuals)
    samples = np.sum(~np.isnan(residuals))
    norm_residuals = residuals/samples

    return residuals, norm_residuals

def iterative_fit(
        input_spectrum,
        degree_sigma,
        degree_width,
        iterations=3,
        guess_spectrum=None,
        fiber="",
        plot_path="",
        use_sigma_lr=True,
        show_plots=False
    ):
    """
    Fits model to etalon spectrum.

    QUICK-FIX (2021-09-08, AS): Replace (not supported) guess parameters
    from guess file with guess spectrum from this file to run guess on the
    data. Useful not as a 'speed-up' but for potentially bad/contaminated
    data that need a good first guess

    TODO: possible refinements:
        - Evaluate the cost function or the change in peak center positions
        as stop criterion.
        - An initial_guess could be used. Typically, we will have a set of data
        that is very similar to each other (e.g. etalon spectra of one day).
        The initial_guess can be used to speed up fitting as long as the
        changes in between spectra are small.

    TODO: at the moment there is only one global function for sigma and sigma1
    and sigma2 is forced to be identical. However, it is more precise to
    describe left and right wings of the peaks with seperate sigmas. -> make
    two global functions to make seperate functional describtion of sigma for
    left and right

    Parameters
    ----------
    spectrum_: np.ndarray
        recorded etalon spectrum
    degree_sigma: int
        degree for the polynomial of the peak sigmas
    degree_width: int
        degree for the polynomial of the peak widths
    iterations: int
        Number of iterations to fit
    guess_spectrum: np.ndarray
        Extracted etalon spectrum from a previous fit (see TODO)
    fibre: str
        fibre to process, this is only used to generate filenames for
        debug plots and for log messages
    plot_path: str
        Generate debug plots and save them at the given location

    Returns
    -------
    FitResult: namedtuple
    """

    log = logutils.get_logger(__name__)
    t0 = time.time()
    # If there is a guess spectrum, use this for the first iteration of fitting data
    if guess_spectrum is not None:
        fit_spectrum = guess_spectrum
        log.info("Use guess spectrum for initial fit")
    else:
        # Otherwise use the input spectrum for the first iteration
        fit_spectrum = input_spectrum

    # Create fit parameters for initial fit
    fit_object = MaroonXFit(
        data=fit_spectrum,
        degree_sigma=degree_sigma,
        degree_width=degree_width,
        fiber=fiber,
        plot_path=plot_path,
        use_sigma_lr=use_sigma_lr
    )

    if plot_path:
        f2 = os.path.join(plot_path, f"initial_guess_{fiber}.{PLOT_FORMAT}")
        fit_object.plot_fit(filename=f2)

    # If provided with the guess spectrum,
    # fit the peak centers using the parameters from the guess file
    if guess_spectrum is not None:
        data = input_spectrum[fit_object.fitrange]
        fit_object.update_maroonxfit(data=data)
        fit_results = fit_object.fit_peak_centers(iteration=0, fiber=fiber)

    shw = fit_object.eval_polynomials()[2, :] #shw is slit half width
    log.info(f"Slit half-width on {fiber} (0. iteration): {shw[0]:.3f} - {shw[-1]:.3f}")

    amplitudes_sorted = np.sort(fit_object.eval_polynomials_at_centers()[1, :])

    log.info(f"Flat-relative amplitudes on {fiber} (0. iteration):\
            min: {amplitudes_sorted[10]}, {amplitudes_sorted[-10]}, median: {np.median(amplitudes_sorted)}")

    #Get the required data to calculate residuals
    spectrum_values = fit_object.spectrum_val()
    data = fit_object.data

    # Calculate residuals
    residuals, norm_residuals = calculate_residuals(data, spectrum_values, 5, True)

    log.info(f"Fit residuals on {fiber} (0. iteration): {residuals:.1f} ({norm_residuals:.3f})")
    log.info(f"Degree sigma: {degree_sigma}, degree width: {degree_width}")
    log.info(f"Created fit parameters for {fiber} in {time.time() - t0:.2f} s")

    if show_plots:
        fit_object.plot_fit()
        plt.show()

    t0 = time.time()

    old_resis_norm = 10 # Set to a high value to ensure that the first iteration is always run
    converged = False

    parameter_list = []
    for i in range(1, iterations):
        t_i = time.time()

        # Save the parameters from the previous iterations in a list.
        # This is used mostly for saving plots
        parameter_list.append(np.copy(fit_object.param_obj.parameters))

        resf = fit_object.fit_polynomials()
        shw = fit_object.eval_polynomials()[2, :]
        amplitudes_sorted = np.sort(fit_object.eval_polynomials_at_centers()[1,:])

        log.info(f"Fitted polynomials ({i}. iteration) on {fiber} in: {time.time() - t_i:.2f} s")
        log.info(f"Slit half-width on {fiber} ({i}. iteration): {shw[0]:.3f} - {shw[-1]:.3f}")
        log.info(f"Flat-relative amplitudes on {fiber} ({i}. iteration):\
                 min: {amplitudes_sorted[10]:.2f}, max: {amplitudes_sorted[-10]:.2f},\
                      median: {np.median(amplitudes_sorted):.2f}")

        t_i = time.time()
        fit_results = fit_object.fit_peak_centers(iteration=i, fiber=fiber)

        log.debug("Fitted centers (%d. iteration) on %s in: %.2f s", i, fiber, time.time() - t_i)

        spectrum_values = fit_object.spectrum_val()
        residuals, resis_norm = calculate_residuals(data, spectrum_values, 3, False)

        log.debug(f"Fit residuals on {fiber} ({i}. iteration):\
                 {residuals:.1f} ({resis_norm:.3f})")

            # If new residuals differ less than 5% from old residuals, stop iterating
        if np.abs(resis_norm - old_resis_norm) < 0.05:
            converged = True
            if resis_norm < old_resis_norm:
                # if we see an improvement, keep the new parameters and increment the iterator
                i = i + 1
            else:
                # If we see no improvement, revert to old parameters
                fit_object.param_obj.update_parameters(parameter_list[-1])
            break
        old_resis_norm = resis_norm

    if converged:
        log.info(f"No more improvement for {fiber} after {i-1} iteration, finished")
    else:
        log.warning(f"Global fit did not converge for {fiber} after {i+1} iteration")

    if show_plots:
        fit_object.plot_fit()
        plt.show()

    if plot_path: # Save the final fit to the path provided
        f1 = os.path.join(plot_path, f"fit_{fiber}.{PLOT_FORMAT}")
        fit_object.plot_fit(filename=f1)
        f2 = os.path.join(plot_path, f"iterations_{fiber}.npz")
        np.savez_compressed(f2, *parameter_list, x=fit_object.fitrange,\
        spectrum=spectrum_values, data=data, bounds=fit_object.parameters_bounds)
        f3 = os.path.join(plot_path, f"meta_parameters_{fiber}.pkl")
        with open(f3, "wb") as f:
            pickle.dump(fit_object.param_obj.meta_parameters, f)

    t_total = time.time() - t0
    log.info(f"Fitting {fiber} done in {t_total:.2f} s")
    return FitResult(fit_object, t_total, iterations, resf, fit_results)
